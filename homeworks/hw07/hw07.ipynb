{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1ef0263",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "#### Homework 7 Supplemental Notebook\n",
    "    \n",
    "# Projections; Regression with Linear Algebra\n",
    "\n",
    "### EECS 245, Fall 2025 at the University of Michigan\n",
    "    \n",
    "</div>\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Most homeworks will have Jupyter Notebooks, like this one, designed to supplement the theoretical problems. \n",
    "\n",
    "To write and run code in this notebook, you have two options:\n",
    "\n",
    "1. **Use the EECS 245 DataHub.** To do this, click the link provided in the Homework 7 PDF. Before doing so, read the instructions on the [**Tech Support**](https://eecs245.org/tech-support/#option-1-using-the-eecs-245-datahub) page on how to use the DataHub.\n",
    "1. **Set up a Jupyter Notebook environment locally, and use `git` to clone our course repository.** For instructions on how to do this, see the [**Tech Support**](https://eecs245.org/tech-support) page of the course website.\n",
    "\n",
    "There are two homework problems mentioned in this notebook:\n",
    "- Problem 3 is contained **entirely** in this notebook, and is **entirely autograded**. To receive credit for Problem 3, submit your completed notebook to the Homework 7, Problem 3 Code autograder on Gradescope. Your submission time for Homework 7 is the **latter** of your PDF and code submission times. Remember that homework problems have hidden test cases. The public test cases in your notebook only verify that your answer is in the correct format and on the right track; your results on the hidden tests will be available to you on Gradescope after we release grades.\n",
    "- Problem 4e) is the only part of Problem 4 that exists in the notebook, but it is **not autograded**: instead, to get credit for it, you'll need to screenshot your implementation of required function and include it in your Homework 7 PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1663c48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Set default layout for all plotly figures\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "custom_template = go.layout.Template(pio.templates[\"plotly_white\"])\n",
    "custom_template.layout.plot_bgcolor = \"white\"\n",
    "custom_template.layout.paper_bgcolor = \"white\"\n",
    "custom_template.layout.margin = dict(l=60, r=60, t=60, b=60)\n",
    "custom_template.layout.width = 700\n",
    "custom_template.layout.font = dict(\n",
    "    family=\"Palatino Linotype, Palatino, serif\",\n",
    "    color=\"black\"\n",
    ")\n",
    "\n",
    "pio.templates[\"custom\"] = custom_template\n",
    "pio.templates.default = \"custom\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ec6c7c",
   "metadata": {},
   "source": [
    "## Problem 3: Billy the Waiter üßë‚Äçüç≥ (14 pts)\n",
    "\n",
    "---\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>Note: In order for this problem to make the most sense, finish Problems 1 and 2 first.</b>\n",
    "</div>\n",
    "\n",
    "Run the cell below to load in a dataset containing information about the tips Billy received over the last month as a waiter at Mani Osteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe66066",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = px.data.tips().rename(columns={'size': 'table_size'}).replace('Fri', 'Thur')\n",
    "tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3c24b5",
   "metadata": {},
   "source": [
    "Each row corresponds to a single table that he served. Throughout this question, our goal will be to predict `tip` using some or all of the other features in the DataFrame. We will do so by implementing all aspects of the linear regression model-building process **manually using `numpy`, i.e. WITHOUT using `sklearn` or other machine learning packages**. In Homework 8, we'll look at how to use `sklearn` to build more advanced linear models.\n",
    "\n",
    "Let's start by just using `total_bill` to predict `tip`. Here's a scatter plot showing the relationship between the two variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0b92a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = tips.plot(kind='scatter', x='total_bill', y='tip', title='Total Bill vs. Tip')\n",
    "# fig.show(renderer='notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaaa0a7",
   "metadata": {},
   "source": [
    "We knew how to build a simple linear regression model that uses `total_bill` to predict `tip` over a month ago, well before we learned about linear algebra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12aa0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_slope(x, y):\n",
    "    return np.corrcoef(x, y)[0, 1] * np.std(y) / np.std(x)\n",
    "\n",
    "def optimal_intercept(x, y):\n",
    "    return np.mean(y) - optimal_slope(x, y) * np.mean(x)\n",
    "\n",
    "w1_star = optimal_slope(tips['total_bill'], tips['tip'])\n",
    "w0_star = optimal_intercept(tips['total_bill'], tips['tip'])\n",
    "print('w1_star: ', w1_star, '\\nw0_star: ', w0_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6871de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted tip for a total bill of $15.\n",
    "w0_star + w1_star * 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4b78f5",
   "metadata": {},
   "source": [
    "But, equipped with our understanding of projections, we can implement the same formulas using linear algebra. That's exactly what we've done for you below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0de4ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_normal_equations(X, y):\n",
    "    '''\n",
    "    Finds w*, as defined in Problem 1 of Homework 7.\n",
    "    Equivalent to returning w* = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "    when X.T @ X is invertible, but more efficient and numerically stable.\n",
    "    '''\n",
    "    return np.linalg.solve(X.T @ X, X.T @ y)\n",
    "\n",
    "def compute_mse(X, y, w):\n",
    "    '''\n",
    "    Returns the mean squared error of the predictions of the model\n",
    "    predicted y = X @ w.\n",
    "    Often used in conjunction with solve_normal_equations, which finds the best w*.\n",
    "    '''\n",
    "    return np.mean((y - X @ w) ** 2)\n",
    "\n",
    "def create_design_matrix(df, columns):\n",
    "    '''\n",
    "    Creates a design matrix X, whose first column is 1, 1, ..., 1,\n",
    "    whose second column contains the first feature, third column contains the second feature, etc.\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    df['1'] = 1\n",
    "    return df[['1'] + columns].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eb16d4",
   "metadata": {},
   "source": [
    "How do we use `solve_normal_equations` and `create_design_matrix`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0daff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_one_feature = create_design_matrix(tips, ['total_bill'])\n",
    "y = tips['tip']\n",
    "\n",
    "# Notice that X_one_feature has two columns.\n",
    "X_one_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6c4810",
   "metadata": {},
   "source": [
    "The vector $\\vec w^*$, found below, finds `w1_star` and `w0_star` in just a single function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b7ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding w*.\n",
    "w_one_feature = solve_normal_equations(X_one_feature, y)\n",
    "w_one_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3276f196",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Before proceeding, make sure you notice the fact that <code>w_one_feature</code>, found using linear algebra, contains both <code>w1_star</code> and <code>w0_star</code>, which we found using calculus at the start of the semester! This equivalence is what you proved in Problem 2 of this homework.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d961db07",
   "metadata": {},
   "source": [
    "We can now use this hypothesis function to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3dddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalent to 1 * w0_star + 15 * w1_star.\n",
    "np.array([1, 15]) @ w_one_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd36940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(tips, x='total_bill', y='tip', title='Tip vs. Total Bill')\n",
    "\n",
    "x_range = np.linspace(0, 60)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=tips['total_bill'], y=y, mode='markers', name='actual'))\n",
    "fig.add_trace(go.Scatter(x=x_range, \n",
    "                         y=w_one_feature[0] + w_one_feature[1] * x_range, \n",
    "                         name='Simple Linear Regression Model', \n",
    "                         line=dict(color='orange')))\n",
    "\n",
    "fig.update_layout(xaxis_title='Total Bill', yaxis_title='Tip')\n",
    "# fig.show(renderer='notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5195b91",
   "metadata": {},
   "source": [
    "The mean squared error of this hypothesis function is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb6830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_one_feature = compute_mse(X_one_feature, y, w_one_feature)\n",
    "mse_one_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1026017",
   "metadata": {},
   "source": [
    "We'll define the DataFrame `hypothesis_functions` solely to keep track of the hypothesis functions we've used so far along with their MSEs. (We'll update this DataFrame for you.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3327c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_functions = pd.DataFrame(index=['total_bill'], columns=['MSE'])\n",
    "hypothesis_functions.loc['total_bill'] = mse_one_feature\n",
    "hypothesis_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee005b0f",
   "metadata": {},
   "source": [
    "### Problem 3a) (2 pts)\n",
    "\n",
    "Let's suppose Billy works for a day as a waiter at the [Gandy Dancer](https://www.gandydancerrestaurant.com/), a fancy restaurant. He waits a table whose total bill is \\$350. He decides to use the above trained model to predict the tip that he will receive.\n",
    "\n",
    "1. What tip would the above single-feature model predict for a total bill of \\$350? In the cell below, assign the answer to the variable `prediction_for_350`. (Try and use the `@` symbol as part of your answer!)\n",
    "1. Is this prediction likely to be accurate? If so, in the cell below, assign the variable `is_accurate` to `True`, otherwise, assign it to `False`. Before assigning `is_accurate` to either `True` or `False`, you should think about what makes a prediction about the future likely to be accurate vs. not.\n",
    "\n",
    "**You should not round any numbers at any point in this question**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5855c5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_for_350 = ...\n",
    "is_accurate = ...\n",
    "\n",
    "# Don't change the line below.\n",
    "print(f'The predicted tip for a total bill of $350 is ${round(prediction_for_350, 2)}, and we {\"do\" if is_accurate else \"do not\"} think this prediction is likely to be accurate.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9264ee",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"p03a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1ed648",
   "metadata": {},
   "source": [
    "### Problem 3b) (2 pts)\n",
    "\n",
    "Now, let's suppose we want to use `total_bill` **and** `table_size` to predict `tip`. This amounts to creating an $n \\times \\mathbf{3}$ design matrix, whose first two columns are the same as in `X_one_feature`, but with a third column containing table sizes.\n",
    "\n",
    "$$X = \\begin{bmatrix} 1 & \\text{total bill}_1 & \\text{table size}_1 \\\\ 1 & \\text{total bill}_2 & \\text{table size}_2 \\\\ \\vdots & \\vdots & \\vdots \\\\ 1 & \\text{total bill}_n & \\text{table size}_n \\end{bmatrix}$$\n",
    "\n",
    "Below, complete the following tasks:\n",
    "\n",
    "1. Assign `X_two_features` to the design matrix for this new hypothesis function.\n",
    "1. Assign `w_two_features` to the optimal parameter vector for this new hypothesis function.\n",
    "1. Assign `mse_two_features` to the mean squared error of this hypothesis function.\n",
    "1. Did adding `table_size` as a feature make our hypothesis function significantly more accurate as compared to the hypothesis function that used just `total_bill`? If so, assign `much_more_accurate` to `True`, otherwise assign it to `False`.\n",
    "\n",
    "Tasks 1, 2, and 3 should each only take line; remember to use the helper functions we've already defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27822530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_two_features = ...\n",
    "w_two_features = ...\n",
    "mse_two_features = ...\n",
    "much_more_accurate = ...\n",
    "\n",
    "# Don't change the lines below.\n",
    "print('first five rows of design matrix:\\n', X_two_features[:5])\n",
    "print('\\noptimal parameter vector:', w_two_features)\n",
    "print('MSE:', mse_two_features)\n",
    "print('much more accurate:', 'yes' if much_more_accurate else 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0726890d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"p03b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b6b45f",
   "metadata": {},
   "source": [
    "If you completed Problem 3b) correctly, you should see a 3D scatter plot of the original data points and your hypothesis function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faaed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "XX, YY = np.mgrid[0:60:2, 0:8:2]\n",
    "Z = w_two_features[0] + w_two_features[1] * XX + w_two_features[2] * YY\n",
    "plane = go.Surface(x=XX, y=YY, z=Z, colorscale='Oranges')\n",
    "\n",
    "fig = go.Figure(data=[plane])\n",
    "fig.add_trace(go.Scatter3d(x=tips['total_bill'], \n",
    "                           y=tips['table_size'], \n",
    "                           z=tips['tip'], mode='markers', marker = {'color': '#3d81f6'}))\n",
    "\n",
    "fig.update_layout(scene = dict(\n",
    "    xaxis_title='Total Bill',\n",
    "    yaxis_title='Table Size',\n",
    "    zaxis_title='Tip'), title='Tip vs. Total Bill')\n",
    "\n",
    "# fig.show(renderer='notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dcf546",
   "metadata": {},
   "source": [
    "Don't change this cell, just run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa504c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_functions.loc['total_bill and table_size'] = mse_two_features\n",
    "hypothesis_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503624d1",
   "metadata": {},
   "source": [
    "### Problem 3c) (2 pts)\n",
    "\n",
    "Which feature is more important in predicting tip ‚Äì `total_bill` or `table_size`?\n",
    "\n",
    "Assuming you answered Problem 3b) correctly, run the cell below to create a **standardized** design matrix, where the two columns for `total_bill` and `tip` are standardized to have mean 0 and standard deviation 1 (i.e. converted to $z$-scores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4ffe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_two_features_standardized = X_two_features.copy()\n",
    "X_two_features_standardized[:, 1:] = (X_two_features[:, 1:] - np.mean(X_two_features[:, 1:], axis=0)) / X_two_features[:, 1:].std(axis=0, ddof=0)\n",
    "X_two_features_standardized[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0a048f",
   "metadata": {},
   "source": [
    "Below,\n",
    "\n",
    "1. Assign `w_two_features_standardized` to an array containing the standardized regression coefficients for our two-feature hypothesis function.\n",
    "1. Assign `more_important` to either `'total_bill'` or `'table_size'`, depending on which of the two features you think is more important in predicting `tip`.\n",
    "\n",
    "_Hint: We haven't talked about standardized regression coefficients in class yet. We want you to think about what standardizing the features actually does._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f4be6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w_two_features_standardized = ...\n",
    "more_important = ...\n",
    "w_two_features_standardized, more_important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80ac6ad",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"p03c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b157883a",
   "metadata": {},
   "source": [
    "Don't change this cell, just run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975c3c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_functions.loc['total_bill and table_size std'] = compute_mse(X_two_features_standardized, y, w_two_features_standardized)\n",
    "hypothesis_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7abeb9",
   "metadata": {},
   "source": [
    "The MSEs of the last two models were the same! The only difference is that when we standardized the features in creating the most recent hypothesis function, we were able to compare the coefficients directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d1f13d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Now, let's revisit the scatter plot of `'tip'` vs. `'total bill'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9885a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(tips, x='total_bill', y='tip', title='Tip vs. Total Bill')\n",
    "fig.update_layout(xaxis_title='Total Bill', yaxis_title='Tip')\n",
    "# fig.show(renderer='notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc24996",
   "metadata": {},
   "source": [
    "Let's see if using higher-degree polynomial features yields a better hypothesis function. Specifically, let's try and create a degree 4 polynomial hypothesis function, using the features `total_bill`, `total_bill^2`, `total_bill^3`, and `total_bill^4`.\n",
    "\n",
    "Again, we recognize that we haven't seen this idea in lecture yet; this part of the problem is meant to give you a taste of how polynomial regression works,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf916c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a copy of the tips DataFrame so that we don't modify the original data.\n",
    "tips_with_poly_features = tips.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b76284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing total_bill^2.\n",
    "tips_with_poly_features['total_bill^2'] = tips_with_poly_features['total_bill'] ** 2\n",
    "tips_with_poly_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97296226",
   "metadata": {},
   "source": [
    "### Problem 3d) (3 pts)\n",
    "\n",
    "Below,\n",
    "\n",
    "1. Add columns `total_bill^3` and `total_bill^4` to the DataFrame `tips_with_poly_features`.\n",
    "1. Define `X_poly`, `w_poly`, and `mse_poly` to be the design matrix, optimal parameter vector, and mean squared error of our new 4th degree polynomial hypothesis function. Note that this hypothesis function should be of the form:\n",
    "\n",
    "    $$h(x_i) = w_0 + w_1 x_i + w_2 x_i^2 + w_3 x_i^3 + w_4 x_i^4$$\n",
    "\n",
    "    where $x$ is the `total_bill`.\n",
    "\n",
    "Again, this subpart should only take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70babe6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tips_with_poly_features = ...\n",
    "X_poly = ...\n",
    "w_poly = ...\n",
    "mse_poly = ...\n",
    "\n",
    "# Don't change the lines below.\n",
    "print('first five rows of design matrix:\\n', X_poly[:5])\n",
    "print('\\noptimal parameter vector:', w_poly)\n",
    "print('MSE:', mse_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f732e8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"p03d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb06c2b",
   "metadata": {},
   "source": [
    "Don't change this cell, just run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25ac54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_functions.loc['total_bill 4th degree poly'] = mse_poly\n",
    "hypothesis_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db3e7d2",
   "metadata": {},
   "source": [
    "Assuming you completed Problem 3d) correctly, run the following cell to see a visualization of our 4th degree polynomial hypothesis function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4655e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = np.linspace(0, 50)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=tips['total_bill'], y=tips['tip'], mode='markers', name='actual'))\n",
    "fig.add_trace(go.Scatter(x=x_range, \n",
    "                         y=w_poly[0] + w_poly[1] * (x_range) + w_poly[2] * (x_range**2) + \\\n",
    "                             w_poly[3] * (x_range**3) + w_poly[4] * (x_range**4),\n",
    "                         name='4th Degree Polynomial Model', \n",
    "                         line=dict(color='orange', width=5)))\n",
    "\n",
    "fig.update_layout(xaxis_title='Total Bill', yaxis_title='Tip', title='Tip vs. Total Bill')\n",
    "# fig.show(renderer='notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d168b43",
   "metadata": {},
   "source": [
    "The 4th degree polynomial hypothesis function seems to fit the data the best so far, since its MSE is the lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1dab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0506fe63",
   "metadata": {},
   "source": [
    "But let's see what happens when we \"zoom out\" and look at how this hypothesis function behaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c80107",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = np.linspace(-20, 70)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=tips['total_bill'], y=tips['tip'], mode='markers', name='actual'))\n",
    "fig.add_trace(go.Scatter(x=x_range, \n",
    "                         y=w_poly[0] + w_poly[1] * (x_range) + w_poly[2] * (x_range**2) + \\\n",
    "                             w_poly[3] * (x_range**3) + w_poly[4] * (x_range**4),\n",
    "                         name='4th Degree Polynomial Model', \n",
    "                         line=dict(color='orange', width=5)))\n",
    "\n",
    "fig.update_layout(xaxis_title='Total Bill', yaxis_title='Tip', title='Tip vs. Total Bill')\n",
    "# fig.show(renderer='notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2440ba",
   "metadata": {},
   "source": [
    "If we keep increasing the degrees of the polynomial features we use, our hypothesis function will look more and more like a polynomial that passes through every single data point. **Think** about **why** a model with a lower MSE is not necessarily better than a model with a higher MSE. You don't need to write your answer anywhere, but discuss it with someone (either a peer or IA/instructor) before submitting this homework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d66ef34",
   "metadata": {},
   "source": [
    "### Problem 3e) (2 pts)\n",
    "\n",
    "Let's again suppose Billy works for a day as a waiter at [The Gandy Dancer](https://www.gandydancerrestaurant.com/). He waits a table whose total bill is \\$350. He decides to use the above 4th degree polynomial hypothesis function to predict the tip that he will receive.\n",
    "\n",
    "What tip would the above polynomial model predict for a total bill of \\$350? In the cell below, assign the answer to the variable `poly_prediction_for_350`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed79eb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "poly_prediction_for_350 = ...\n",
    "\n",
    "# Don't change the line below.\n",
    "print(f'The predicted tip for a total bill of $350 is ${round(poly_prediction_for_350, 2)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a1c4b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"p03e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd27b418",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "There was another column in our original DataFrame, `tips`, that we haven't yet looked at: `day`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6996f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e32afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(tips['day'].value_counts().loc[['Thur', 'Sat', 'Sun']])\n",
    "# fig.show(renderer='notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574c3837",
   "metadata": {},
   "source": [
    "Note that unlike `total_bill` and `table_size`, `day` is **categorical**. This means there's no easy way to put it in our design matrix or find the best hypothesis function.\n",
    "\n",
    "A na√Øve solution would be to encode `'Thur'` as 1, `'Sat'` as 2, and `'Sun'` as 3, but this would make it seem like Sunday is \"more\" than Saturday or Thursday in some regard, which it is not ‚Äì these are all just different days of the week.\n",
    "\n",
    "A more robust and common solution is called **one hot encoding** (OHE). To show you how it works, we'll first get it working on a toy example. Let's pretend we have a DataFrame with just 5 rows and 2 columns, `total_bill` and `day`. Call it `mini_tips`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef898d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_tips = pd.DataFrame()\n",
    "mini_tips['total_bill'] = tips['total_bill'].iloc[:5]\n",
    "mini_tips['day'] = ['Sat', 'Sun', 'Sun', 'Thur', 'Sat']\n",
    "mini_tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c208ab3",
   "metadata": {},
   "source": [
    "When we **one hot encode** a categorical variable, we create a new column for each unique value of that categorical variable. In this case, we'd create three new columns, one each for `'Thur'`, `'Sat'`, and `'Sun'`.\n",
    "\n",
    "Each of these new columns is binary, meaning they only contain the values 1 and 0. \n",
    "- The new column for `'Thur'`, which we'll call `is_thur`, will contain a 1 for rows where the value of `'day'` is `'Thur'`, and 0 for all other rows. \n",
    "- Similarly, the new column for `'Sun'`, which we'll call `is_sun`, will contain a 1 for rows where the value of day is `'Sun'`, and 0 for all other rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4364f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(mini_tips['day'] == 'Thur')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e5b12b",
   "metadata": {},
   "source": [
    "Repeating this for all columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6723bb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_tips['is_thur'] = (mini_tips['day'] == 'Thur').astype(int)\n",
    "mini_tips['is_sat'] = (mini_tips['day'] == 'Sat').astype(int)\n",
    "mini_tips['is_sun'] = (mini_tips['day'] == 'Sun').astype(int)\n",
    "\n",
    "# Dropping the 'day' column. We've encoded it numerically, we don't need it anymore.\n",
    "mini_tips = mini_tips.drop(columns=['day'])\n",
    "mini_tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056049c1",
   "metadata": {},
   "source": [
    "Now we've converted a categorical feature into three numerical features, so we're good to go!\n",
    "\n",
    "**There's just one more thing.** Since we're used to fitting linear hypothesis functions with an intercept term, our design matrix generally has a column of all 1s in it. In the case of `mini_tips`, which contains three binary columns, this would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f12d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_design_matrix(mini_tips, list(mini_tips.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2db537d",
   "metadata": {},
   "source": [
    "This design matrix contains redundant information! Specifically, we can recreate the column of all 1s by adding together the three one hot encoded columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ede37ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the 0, 1, 2, 3, 4 that you see is the index of this Series, which is irrelevant for our purposes.\n",
    "mini_tips['is_thur'] + mini_tips['is_sat'] + mini_tips['is_sun']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c33a35",
   "metadata": {},
   "source": [
    "What this means is $X$'s columns aren't linearly independent, so $X^TX$ (which has the same rank as $X$) is not **full rank** and hence is **not invertible**.\n",
    "\n",
    "This means that a unique minimizer\n",
    "\n",
    "$$w^* = (X^TX)^{-1}X^T \\vec y$$\n",
    "\n",
    "doesn't exist, and instead, there are infinitely many optimal $\\vec w^*$'s that minimize mean squared error. These all satisfy the **normal equations**,\n",
    "\n",
    "$$X^TX \\vec w^* = X^T \\vec y$$\n",
    "\n",
    "Again, we'll address this idea in lectures to come, so don't worry if this is a bit confusing. This is more meant to be a preview.\n",
    "\n",
    "**For now, know this ‚Äì the way to avoid this problem is to drop one of the one hot encoded columns.** That way, there is no redundant information in the design matrix, and we don't run into any issues. This is not \"getting rid\" of any information, so it will not impact our predictions ‚Äì if we know it is not Saturday or Sunday, it must be Thursday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bd3b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've arbitrarily chosen to drop 'is_thur', but it would make no difference if we instead dropped 'is_sat' or 'is_sun'.\n",
    "mini_tips = mini_tips.drop(columns=['is_thur'])\n",
    "mini_tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c70dabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_design_matrix(mini_tips, list(mini_tips.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3553b34a",
   "metadata": {},
   "source": [
    "Now we have a design matrix that is ready to go. Let's replicate this process on our full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8622f930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell.\n",
    "tips_ohe = tips.copy()\n",
    "tips_ohe['is_sat'] = (tips_ohe['day'] == 'Sat').astype(int)\n",
    "tips_ohe['is_sun'] = (tips_ohe['day'] == 'Sun').astype(int)\n",
    "\n",
    "# Design matrix with two one-hot encoded columns.\n",
    "X_ohe = create_design_matrix(tips_ohe, ['total_bill', 'is_sat', 'is_sun'])\n",
    "print('first five rows of design matrix:\\n', X_ohe[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1140fea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ohe = solve_normal_equations(X_ohe, y)\n",
    "w_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e6257b",
   "metadata": {},
   "source": [
    "Let's now plot the resulting hypothesis function. We've zoomed into the region where the `total_bill`s are less than \\\\$30 and `tip`s are less than \\\\$4 to make the hypothesis function more clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f837acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = np.linspace(0, 30)\n",
    "\n",
    "under_30 = tips[(tips['total_bill'] < 30) & (tips['tip'] < 4)]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=under_30['total_bill'], y=under_30['tip'], mode='markers', name='actual'))\n",
    "\n",
    "# Line for Thursday.\n",
    "fig.add_trace(go.Scatter(x=x_range, \n",
    "                         y=w_ohe[0] + w_ohe[1] * x_range, \n",
    "                         name='Thursday', \n",
    "                         line=dict(color='orange', width=4)))\n",
    "\n",
    "# Line for Saturday.\n",
    "fig.add_trace(go.Scatter(x=x_range, \n",
    "                         y=w_ohe[0] + w_ohe[2] + w_ohe[1] * x_range, \n",
    "                         name='Saturday', \n",
    "                         line=dict(color='purple', width=4)))\n",
    "\n",
    "# Line for Sunday.\n",
    "fig.add_trace(go.Scatter(x=x_range, \n",
    "                         y=w_ohe[0] + w_ohe[3] + w_ohe[1] * x_range, \n",
    "                         name='Sunday', \n",
    "                         line=dict(color='green', width=4)))\n",
    "\n",
    "fig.update_layout(xaxis_title='Total Bill', yaxis_title='Tip', title='Tip vs. Total Bill')\n",
    "# fig.show(renderer='notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a747f0f",
   "metadata": {},
   "source": [
    "It looks like the model is actually three separate lines, each of which have the same slope but different intercepts!\n",
    "\n",
    "Let's try and understand why this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a60dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01109ed3",
   "metadata": {},
   "source": [
    "Our hypothesis function is of the following form (approximately, since the coefficients are rounded):\n",
    "\n",
    "$$\\text{predicted tip}_i = 0.925 + 0.105 (\\text{total bill}_i) - 0.072 (\\text{is saturday}_i) + 0.089 (\\text{is sunday}_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a44aa7f",
   "metadata": {},
   "source": [
    "### Problem 3f) (3 pts)\n",
    "\n",
    "Below, assign `intercept_thur`, `intercept_sat`, and `intercept_sun` to the **$y$-intercepts** of the three lines above, corresponding to when the `'day'` is Thursday, Saturday, or Sunday. You should do this using code,  pulling values from `w_ohe`, but you should think conceptually about where each of the three intercepts are coming from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344d8874",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "intercept_thur = ...\n",
    "intercept_sat = ...\n",
    "intercept_sun = ...\n",
    "\n",
    "# Don't change the lines below.\n",
    "print('Intercept for Thursday:', intercept_thur)\n",
    "print('Intercept for Saturday:', intercept_sat)\n",
    "print('Intercept for Sunday:', intercept_sun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fdb157",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"p03f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae57857",
   "metadata": {},
   "source": [
    "Just for completeness, we'll also compute the MSE of this hypothesis function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49472501",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_ohe = compute_mse(X_ohe, y, w_ohe)\n",
    "hypothesis_functions.loc['total_bill + OHE day'] = mse_ohe\n",
    "hypothesis_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7365e6",
   "metadata": {},
   "source": [
    "This new hypothesis function didn't have a much lower MSE than the hypothesis function that used `total_bill` only. That's not all that surprising, since the three lines above look quite similar.\n",
    "\n",
    "That's all for this problem! Remember, this problem is entirely autograded, and has some hidden tests. Make sure to submit it to the Homework 7, Problem 3 autograder on Gradescope and verify all public tests pass there. \n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>Make sure you also understand how one hot encoding works, since it's likely to be a topic that appears on Midterm 2.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad511627",
   "metadata": {},
   "source": [
    "## Problem 4: Orthogonalization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a03d9ff",
   "metadata": {},
   "source": [
    "The entirety of Problem 4 is manually graded; all you need to do here is implement the function `orthogonalize` below and include screenshots of your implementation and its outputs. As usual, there are <span style=\"color: orange; font-weight: bold\">orange lines</span> around what you need to screenshot.\n",
    "\n",
    "First, allow us to give you some hints on how to work with arrays. Consider the following examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0329918",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[3, 5],\n",
    "              [1, 2],\n",
    "              [4, 0],\n",
    "              [0, 3],\n",
    "              [9, -2]])\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de30d82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dee62f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:, 1].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cc759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b7fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros_like(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83ff427",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.eye(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8462222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coupled with the above, you can use np.eye and np.allclose to\n",
    "# verify that you implemented orthogonalize correctly!\n",
    "np.allclose([[3, 4]], [[2.9999999999, 4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af88d68d",
   "metadata": {},
   "source": [
    "### Problem 4e)\n",
    "\n",
    "Complete the implementation of the function `orthogonalize`, which takes in an $n \\times d$ matrix $V$ (stored as a 2D array) whose columns are linearly independent, and returns an $n \\times d$ matrix $Q$ (also stored as a 2D array) whose columns are orthonormal and span the same subspace of $\\mathbb{R}^n$ that $V$'s columns do.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    "# This is the example we walked through in Problem 4.\n",
    ">>> orthogonalize(np.array([[1.0,  1.0, 1.0],\n",
    "                            [-1.0, 0.0, 1.0],\n",
    "                            [1.0,  1.0, 2.0]]))\n",
    "array([[ 5.77350269e-01,  4.08248290e-01, -7.07106781e-01],\n",
    "       [-5.77350269e-01,  8.16496581e-01, -3.14018492e-16],\n",
    "       [ 5.77350269e-01,  4.08248290e-01,  7.07106781e-01]])\n",
    "```\n",
    "\n",
    "Feel free to implement helper functions if you'd like (we did).\n",
    "\n",
    "<hr style=\"border: 0; height: 4px; background: orange;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0a4be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orthogonalize(V):\n",
    "    \"\"\"\n",
    "    Runs the Gram-Schmidt process on the columns of V.\n",
    "    The shape of Q should be the same as the shape of V.\n",
    "    Assume V has at least 1 column and 1 row.\n",
    "    \"\"\"\n",
    "    V = V.copy() # Ensures that you don't make any modifications to the underlying array.\n",
    "    ...\n",
    "    \n",
    "# Feel free to test out your implementation below.\n",
    "# Recent versions of numpy will error if you try and perform operations involving\n",
    "# an array of ints and an array of floats, which is why we've initialized the array with floats.\n",
    "orthogonalize(np.array([[4.0, 1.0], \n",
    "                        [3.0, 5.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795bda61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL;\n",
    "# include a screenshot of the output of this cell in your submitted PDF.\n",
    "V_test_1 = np.array([[1.0,  1.0, 1.0],\n",
    "                     [-1.0, 0.0, 1.0],\n",
    "                     [1.0,  1.0, 2.0]])\n",
    "Q_test_1 = orthogonalize(V_test_1)\n",
    "Q_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db94a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL;\n",
    "# include a screenshot of the output of this cell in your submitted PDF.\n",
    "V_test_2 = np.array([[3, 5, 4, 0],\n",
    "                     [1, 0, 9, -1],\n",
    "                     [5, 1, 3, 2],\n",
    "                     [0, 8, 0, 8],\n",
    "                     [3, 2, -1.5, 4],\n",
    "                     [0, 0, 0, 1]])\n",
    "Q_test_2 = orthogonalize(V_test_2)\n",
    "Q_test_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e35784",
   "metadata": {},
   "source": [
    "<hr style=\"border: 0; height: 4px; background: orange;\">\n",
    "\n",
    "In your submission for Problem 4e), make sure to include screenshots of:\n",
    "- Your implementations of `orthogonalize` **and** any helper functions you defined.\n",
    "- The inputs and outputs for the cells involving `V_test_1` and `V_test_2`.\n",
    "\n",
    "Feel free to experiment beyond these test cases, but you don't have to screenshot any additional code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95646789",
   "metadata": {},
   "source": [
    "### Problem 4f)\n",
    "\n",
    "This is not a programming problem, but you might want to use your implementation of `orthogonalize` to figure out how $A = QR$ works. A pretty big hint is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe308247",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[2.0,  1, -2],\n",
    "              [1,    4, -5],\n",
    "              [-4,   3,  6],\n",
    "              [1,    0,  9]])\n",
    "\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f53b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = orthogonalize(A)\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaafd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q @ Q.T @ A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404468b1",
   "metadata": {},
   "source": [
    "No part of the code above needs to be included in your notebook for Problem 4f)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7ae388",
   "metadata": {},
   "source": [
    "## Finish Line üèÅ\n",
    "\n",
    "Remember:\n",
    "1. To get credit for Problem 3, submit this notebook to Gradescope.\n",
    "    1. Select `Kernel -> Restart & Run All` to ensure that you have executed all cells, including the test cells.\n",
    "    2. Read through the notebook to make sure everything is fine and all public tests passed.\n",
    "    3. Run the cell below to run all tests, and make sure that they all pass.\n",
    "    4. Download your notebook using `File -> Download`, then upload your notebook to Gradescope under \"Homework 7, Problem 3 Code\".\n",
    "    5. Stick around for a few minutes while the Gradescope autograder grades your work. Make sure you see that all **public tests** have passed on Gradescope. **Remember that homeworks have hidden tests!**\n",
    "2. To get credit for Problem 4e), include a screenshot of your implementation of `orthogonalize` and the outputs of the two provided tests in your Homework 7 PDF."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "otter": {
   "tests": {
    "p03a": {
     "name": "p03a",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(prediction_for_350, float) and isinstance(is_accurate, bool)\nTrue",
         "failure_message": "Make sure prediction_for_350 is a float and is_accurate is a bool,",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "p03b": {
     "name": "p03b",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(X_two_features, np.ndarray) and X_two_features.shape == (244, 3)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(w_two_features, np.ndarray) and w_two_features.shape == (3,)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(mse_two_features, float) and mse_two_features > 1\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(much_more_accurate, bool)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "p03c": {
     "name": "p03c",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(w_two_features_standardized, np.ndarray) and len(w_two_features_standardized) == 3\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.all(np.diff(w_two_features_standardized) < 0) # Making sure the coefficients are in the right order.\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> more_important in ['total_bill', 'table_size']\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> more_important == 'total_bill'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "p03d": {
     "name": "p03d",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> tips_with_poly_features.shape == (244, 10) and set(tips_with_poly_features.columns) >= set(['total_bill', 'total_bill^2', 'total_bill^3', 'total_bill^4'])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(X_poly, np.ndarray) and X_poly.shape == (244, 5)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(w_poly, np.ndarray) and w_poly.shape == (5,)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(mse_poly, float) and mse_poly < 1\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "p03e": {
     "name": "p03e",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(poly_prediction_for_350, float)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "p03f": {
     "name": "p03f",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(intercept_thur, float) and isinstance(intercept_sat, float) and isinstance(intercept_sun, float)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> intercept_sat < intercept_thur < intercept_sun\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(intercept_thur, w_ohe[0], atol=0.05) or np.isclose(intercept_thur, 0.9251166109157465, atol=0.05)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
